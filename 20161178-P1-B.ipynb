{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, re\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import *\n",
    "init_notebook_mode(connected=True)\n",
    "import string\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (open('Data/train.txt').read()).split('\\n')\n",
    "dev = (open('Data/dev.txt').read()).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    index = 0;\n",
    "    ls = ['@','@']\n",
    "    new1 = []\n",
    "    for i in data:\n",
    "        if i != '.':\n",
    "            ls.append(i)\n",
    "        else:\n",
    "            ls.append('.')\n",
    "            new1.append(ls)\n",
    "            ls = ['@', '@']\n",
    "    i = 0\n",
    "    for sentence in new1:\n",
    "        sentence = list(filter(None, sentence))\n",
    "        new1[i] = sentence\n",
    "        i=i+1 \n",
    "    return new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenize(train)\n",
    "dev = tokenize(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(n, corpus):\n",
    "    my_dict = dict()\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        for i in range(0, len(sentence) - (n - 1)):\n",
    "            if n == 1:\n",
    "                key = sentence[i]\n",
    "            else:\n",
    "                key = tuple(sentence[i : i + n])   \n",
    "            if key in my_dict:\n",
    "                my_dict[key] += 1\n",
    "            else:\n",
    "                my_dict[key] = 1\n",
    "    return my_dict\n",
    "train_grams = language_model(3, train)\n",
    "train_uni_grams = language_model(1, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyDict = [\"Vt\", \"Vm\", \"V0\", \"Vform\", \"SVA\", \"ArtOrDet\", \"Nn\", \"Npos\", \"Pform\", \"Pref\", \"Prep\", \"Wci\", \"Wa\", \n",
    "       \"Wform\", \"Wtone\", \"Srun\", \"Smod\", \"Spar\", \"Sfrag\", \"Ssub\", \"WOinc\", \"WOadv\", \"Trans\", \"Mec\", \"Rloc-\",\n",
    "       \"Cit\", \"Others\", \"Um\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_classes(corpus):\n",
    "    classes = dict([(keys, []) for keys in keyDict])\n",
    "    for keys in corpus:\n",
    "        if ' ' in keys[2]:\n",
    "            p = keys[2].split(' ')\n",
    "            p = list(filter(None, p))\n",
    "            classes[p[-1]].append(keys)\n",
    "    return classes\n",
    "\n",
    "def fill_classes_uni(corpus):\n",
    "    classes = dict([(keys, []) for keys in keyDict])\n",
    "    for keys in corpus:\n",
    "        if ' ' in keys:\n",
    "            p = keys.split(' ')\n",
    "            p = list(filter(None, p))\n",
    "            classes[p[-1]].append(keys)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = fill_classes(train_grams)\n",
    "uni_classes = fill_classes_uni(train_uni_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words_class(cls, model, corpus):\n",
    "    sum_words = 0\n",
    "    for i in model[cls]:\n",
    "        sum_words += corpus[i]\n",
    "    return sum_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_prob(seq):\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    for i in train_grams:\n",
    "        p1 = list(filter(None, i[0].split(' ')))\n",
    "        p2 = list(filter(None, i[1].split(' ')))\n",
    "        p3 = list(filter(None, i[2].split(' '))) \n",
    "        if p1[0] == seq[0] and p2[0] == seq[1] and p3[0] == seq[2]: \n",
    "            count1 = count1 + train_grams[i]\n",
    "        if p2[0] == seq[1] and p3[0] == seq[2]:\n",
    "            count2 = count2 + train_grams[i]\n",
    "        if p3[0] == seq[2]:\n",
    "            count3 = count3 + train_grams[i]\n",
    "            \n",
    "    return [count1, count2, count3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(seq):\n",
    "    counts = seq_prob(seq)\n",
    "    prob_dict = dict()\n",
    "    for key in classes:\n",
    "        count = 0\n",
    "        for grams in classes[key]:\n",
    "            p1 = list(filter(None, grams[0].split(' ')))\n",
    "            p2 = list(filter(None, grams[1].split(' ')))\n",
    "            p3 = list(filter(None, grams[2].split(' ')))\n",
    "            if counts[0] != 0:\n",
    "                if p1[0] == seq[0] and p2[0] == seq[1] and p3[0] == seq[2]: \n",
    "                    count = count + train_grams[grams]\n",
    "            elif counts[1] != 0:\n",
    "                if p2[0] == seq[1] and p3[0] == seq[2]:\n",
    "                    count = count + train_grams[grams]\n",
    "            elif p3[0] == seq[2]:\n",
    "                count = count + train_grams[grams]      \n",
    "        \n",
    "        if counts[0] != 0:\n",
    "            prob_s_c = (count / total_words_class(key, classes, train_grams))\n",
    "        elif counts[1] != 0:\n",
    "            prob_s_c = 0.08 * (count / total_words_class(key, classes, train_grams))\n",
    "        else:\n",
    "            prob_s_c = 0.008 * (count / total_words_class(key, classes, train_grams))\n",
    "        \n",
    "        prob_c = (total_words_class(key, uni_classes, train_uni_grams))/sum(train_uni_grams.values())\n",
    "        prob_dict[key] = prob_s_c\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_in_clss = dict()\n",
    "for key in classes:\n",
    "    counts_in_clss[key] = total_words_class(key, uni_classes, train_uni_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "uid": "cdbf466a-b4f0-11e8-9939-204747493588",
         "x": [
          "Vt",
          "Vm",
          "V0",
          "Vform",
          "SVA",
          "ArtOrDet",
          "Nn",
          "Npos",
          "Pform",
          "Pref",
          "Prep",
          "Wci",
          "Wa",
          "Wform",
          "Wtone",
          "Srun",
          "Smod",
          "Spar",
          "Sfrag",
          "Ssub",
          "WOinc",
          "WOadv",
          "Trans",
          "Mec",
          "Rloc-",
          "Cit",
          "Others",
          "Um"
         ],
         "y": [
          2972,
          451,
          350,
          1259,
          1206,
          5199,
          3053,
          250,
          173,
          864,
          1799,
          6449,
          48,
          1716,
          1463,
          1288,
          208,
          699,
          551,
          510,
          2892,
          731,
          1567,
          2686,
          7752,
          1577,
          1607,
          7840
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"66427386-ad5b-4e72-bd22-a529739f8d18\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"66427386-ad5b-4e72-bd22-a529739f8d18\", [{\"x\": [\"Vt\", \"Vm\", \"V0\", \"Vform\", \"SVA\", \"ArtOrDet\", \"Nn\", \"Npos\", \"Pform\", \"Pref\", \"Prep\", \"Wci\", \"Wa\", \"Wform\", \"Wtone\", \"Srun\", \"Smod\", \"Spar\", \"Sfrag\", \"Ssub\", \"WOinc\", \"WOadv\", \"Trans\", \"Mec\", \"Rloc-\", \"Cit\", \"Others\", \"Um\"], \"y\": [2972, 451, 350, 1259, 1206, 5199, 3053, 250, 173, 864, 1799, 6449, 48, 1716, 1463, 1288, 208, 699, 551, 510, 2892, 731, 1567, 2686, 7752, 1577, 1607, 7840], \"type\": \"scatter\", \"uid\": \"cdbf466b-b4f0-11e8-9939-204747493588\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"66427386-ad5b-4e72-bd22-a529739f8d18\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"66427386-ad5b-4e72-bd22-a529739f8d18\", [{\"x\": [\"Vt\", \"Vm\", \"V0\", \"Vform\", \"SVA\", \"ArtOrDet\", \"Nn\", \"Npos\", \"Pform\", \"Pref\", \"Prep\", \"Wci\", \"Wa\", \"Wform\", \"Wtone\", \"Srun\", \"Smod\", \"Spar\", \"Sfrag\", \"Ssub\", \"WOinc\", \"WOadv\", \"Trans\", \"Mec\", \"Rloc-\", \"Cit\", \"Others\", \"Um\"], \"y\": [2972, 451, 350, 1259, 1206, 5199, 3053, 250, 173, 864, 1799, 6449, 48, 1716, 1463, 1288, 208, 699, 551, 510, 2892, 731, 1567, 2686, 7752, 1577, 1607, 7840], \"type\": \"scatter\", \"uid\": \"cdbf466b-b4f0-11e8-9939-204747493588\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iplot([{\"x\" : [''.join(x) for x in list(zip(*list(counts_in_clss.items())))[0]], \"y\": list(zip(*list(counts_in_clss.items())))[1]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_key_dict = {\"Vt\":10**-4, \"Vm\":10**-6, \"V0\":10**-6, \"Vform\":10**-4, \"SVA\":10**-5, \n",
    "           \"ArtOrDet\":10**-3, \"Nn\":10**-4, \"Npos\":10**-6, \"Pform\":10**-6, \"Pref\":10**-5, \n",
    "           \"Prep\":10**-5, \"Wci\":10**-4, \"Wa\":10**-7, \"Wform\":10**-5, \"Wtone\":10**-5, \n",
    "           \"Srun\":10**-5, \"Smod\":10**-7, \"Spar\":10**-6, \"Sfrag\":10**-6, \"Ssub\":10**-6, \n",
    "           \"WOinc\":10**-4, \"WOadv\":10**-5, \"Trans\":10**-1, \"Mec\":10**-5, \"Rloc-\":10**-5,\n",
    "       \"Cit\":10**-5, \"Others\":10**-5, \"Um\":10**-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"dev_results.txt\")\n",
    "f = open(\"dev_results.txt\", \"a\")\n",
    "for lst in dev:\n",
    "    for i in range(0, len(lst) - 2):\n",
    "        temp = tuple(lst[i : i + 3])\n",
    "        prob_dict = naive_bayes(temp)\n",
    "        clss = max(prob_dict, key = prob_dict.get)\n",
    "        if prob_dict[clss] > prob_key_dict[clss]:\n",
    "            f.write(temp[2] + '      ' + clss + '\\n')\n",
    "        else:\n",
    "            f.write(temp[2] + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lst in dev[0:3]:\n",
    "#     for i in range(0, len(lst) - 2):\n",
    "#         temp = tuple(lst[i : i + 3])\n",
    "#         prob_dict, counts = naive_bayes(temp)\n",
    "#         clss = max(prob_dict, key = prob_dict.get)\n",
    "#         if prob_dict[clss] > prob_key_dict[clss]:\n",
    "#             print(temp[2], '   ', clss, '   ', correction(clss, temp, classes, counts))\n",
    "#         else:\n",
    "#             print(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correction(cls, seq, grams, counts):\n",
    "#     selected_key = 0\n",
    "#     for key in grams[cls]:           \n",
    "#         p1 = list(filter(None, key[0].split(' ')))\n",
    "#         p2 = list(filter(None, key[1].split(' ')))\n",
    "#         p3 = list(filter(None, key[2].split(' ')))\n",
    "#         if counts[0] != 0:\n",
    "#             if p1[0] == seq[0] and p2[0] == seq[1] and p3[0] == seq[2]:\n",
    "#                 if selected_key == 0:\n",
    "#                     selected_key = key\n",
    "#                 elif train_grams[key] > train_grams[selected_key]:\n",
    "#                     selected_key = key\n",
    "#         elif counts[1] != 0:\n",
    "#             if p2[0] == seq[1] and p3[0] == seq[2]:\n",
    "#                 if selected_key == 0:\n",
    "#                     selected_key = key\n",
    "#                 elif train_grams[key] > train_grams[selected_key]:\n",
    "#                     selected_key = key\n",
    "#         elif p3[0] == seq[2]:\n",
    "#                 if selected_key == 0:\n",
    "#                     selected_key = key\n",
    "#                 elif train_grams[key] > train_grams[selected_key]:\n",
    "#                     selected_key = key\n",
    "#     p3 = list(filter(None, selected_key[2].split(' ')))\n",
    "#     return p3[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
